# Server (Node/Express) – Storage & Backups

This server supports storing uploads and backups either on local disk or in Google Drive using a service account.

## Environment

Required (Drive mode):
- STORAGE_PROVIDER=drive
- GOOGLE_DRIVE_FOLDER_ID=1BLOsfrkUBRR0ZxQgLgxmHHXgDkeO5Oy0
- GOOGLE_SERVICE_ACCOUNT_KEY=absolute/path/to/service-account.json (optional; defaults to `server/config/service-account.json`)

Optional:
- CLIENT_ORIGIN, SERVER_HOST, SERVER_PORT, EMAIL_USER/PASS … (existing)

To use local storage instead, omit STORAGE_PROVIDER or set it to `local`.

## How it works

- Abstraction in `utils/storageProvider.js` exposes:
  - storageUpload({ buffer|readableStream, filename, mimeType })
  - storageGetStream(idOrName)
  - storageList()
  - storageDelete(idOrName)
- Google Drive implementation in `utils/googleDriveStorage.js` handles upload/list/stream/delete.
- Backups are generated by `utils/backupWorker.js`. When `STORAGE_PROVIDER=drive`, results are uploaded to Drive and the BackupJob records `provider=drive`, `fileId`, and `resultPath=drive:<filename>`.
- Downloading backup results streams from Drive when provider is drive.

## Routes

- POST /api/uploads (multipart field `file`): upload file to Drive/local
- GET /api/uploads: list files
- GET /api/uploads/:id: download by Drive fileId or local filename
- DELETE /api/uploads/:id: delete by Drive fileId or local filename

- POST /api/dev/backup-jobs: enqueue backup (JSON or CSV)
- GET /api/dev/backup-jobs: list jobs
- GET /api/dev/backup-jobs/:id/download: stream result from Drive/local

## Sharing the Drive Folder

Share the folder with your service account email (from `service-account.json`). Ensure Drive API is enabled on the project.

## Notes

- For very large backups, consider streaming to a temp file then uploading to reduce memory usage.
- Add retention policies or encryption as needed.
# Server API (Calendar Bulk Uploads)

This document supplements the existing backend by describing the new bulk upload endpoints for Local Holidays and Suspension Days.

## Endpoints

### POST /api/local-holidays/bulk-upload
Bulk create local holidays from either a CSV file (multipart/form-data) or a JSON payload containing rows.

Accepts:
1. Multipart form with field `file` (CSV)
2. JSON body: `{ "rows": [ { ...rowFields } ] }`

Flexible headers / keys (case-insensitive):
- name | Name | Holiday | holiday
- date | Date | startDate | StartDate | from | From (required)
- endDate | EndDate | to | To (optional)
- location | Location (optional)
- notes | Notes (optional)

Sample JSON request body:
```json
{
  "rows": [
    { "name": "City Charter Day", "date": "2025-01-05", "location": "Quezon City" },
    { "Holiday": "Festival Week", "from": "2025-02-10", "to": "2025-02-14" }
  ]
}
```

Successful response:
```json
{
  "success": true,
  "count": 2,
  "skipped": 0,
  "invalidRows": []
}
```

### POST /api/suspensions/bulk-upload
Bulk create suspension day entries.

Accepts CSV `file` or JSON `{ rows: [...] }` like above.

Flexible headers / keys:
- title | Title | Subject | subject (required)
- date | Date | startDate | StartDate | from | From (required)
- endDate | EndDate | to | To (optional)
- scope | Scope (defaults to "Local" if missing)
- location | Location (optional)
- referenceType | ReferenceType (defaults to "Memorandum")
- referenceNo | ReferenceNo (optional)
- notes | Notes (optional)
- active | Active (optional; any value "false" (case-insensitive) marks inactive)

Sample JSON:
```json
{
  "rows": [
    { "title": "Office Disinfection", "date": "2025-03-01", "scope": "Local", "active": "false" },
    { "Subject": "Storm Suspension", "from": "2025-07-10", "to": "2025-07-11", "scope": "Regional", "referenceType": "Proclamation" }
  ]
}
```

Successful response:
```json
{
  "success": true,
  "count": 2,
  "skipped": 0,
  "invalidRows": []
}
```

## Validation & Feedback
- Each row is validated for required name/title and a parsable date.
- Invalid rows are reported in `invalidRows` with `{ index, reason }` (first 50 only if large).
- Response includes `count` of inserted documents and `skipped` count.

## Audit Logging
Both bulk upload endpoints create an `AuditLog` entry:
- action: `bulk-upload:local-holidays` or `bulk-upload:suspensions`
- details: `{ inserted, skipped }`

## Preview Workflow (Front-End)
The front-end parses CSV/XLS/XLSX client-side using the `xlsx` library, shows a preview table, then POSTs a JSON `{ rows: [...] }` payload to the server. This prevents partially malformed uploads and lets users review before committing.

## Date Parsing
Dates are parsed with `dayjs(val)`. Use ISO `YYYY-MM-DD` format to avoid locale ambiguities.

## Error Responses
- 400: Missing file or no valid rows.
- 500: Unexpected server error (response contains `message`).

## Future Enhancements (Suggested)
- Optional `dryRun=true` query to validate without inserting.
- Per-row granular error codes.
- Support for ODS (convert client-side then send JSON rows).
- Return inserted document IDs for immediate UI reconciliation.

---
Updated: 2025-11-11
